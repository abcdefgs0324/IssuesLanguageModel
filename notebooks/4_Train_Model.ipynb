{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import TextLMDataBunch as lmdb, load_data\n",
    "from fastai.text.learner import language_model_learner\n",
    "from fastai.text.models import AWD_LSTM\n",
    "from fastai.callbacks import EarlyStoppingCallback, SaveModelCallback, ReduceLROnPlateauCallback, CSVLogger\n",
    "from fastai.text.models import AWD_LSTM\n",
    "from fastai.train import ShowGraph\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/ds/hamel/mdtokenizer/notebooks/lang_model')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('lang_model/')\n",
    "path.absolute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load DataBunch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to redefine or import any custom you defined in the last step, because the data bunch is going to look for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_through(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = load_data(path, bs=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Instantiate Language Model\n",
    "\n",
    "We are going to use the `awd_lstm` with the default parameters listed in the config file below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.models import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data=data_lm,\n",
    "                               arch=AWD_LSTM,\n",
    "                               pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = 1e-2 * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "escb = EarlyStoppingCallback(learn=learn, patience=5)\n",
    "smcb = SaveModelCallback(learn=learn)\n",
    "rpcb = ReduceLROnPlateauCallback(learn=learn, patience=3)\n",
    "sgcb = ShowGraph(learn=learn)\n",
    "csvcb = CSVLogger(learn=learn)\n",
    "\n",
    "callbacks = [escb, smcb, rpcb, sgcb, csvcb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.distributed import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (16385650 items)\n",
       "x: LMTextList\n",
       "xxbos xxxfldtitle xxunk throws exception when adding product via xxup api xxxfldbody xxmaj if xxmaj google xxmaj contents xxmaj experiments is enabled , adding a product using the xxxcdb xxup v1 / products / xxxcde endpoint causes xxunk xxxfilepath line 117 to throw xxxcdb invalidargumentexception xxxcde . xxmaj with contents experiments disabled the product add completes successfully . xxmaj example valid request json : \n",
       "  xxxcdb \" product \" : xxxjson \n",
       "  xxxcde,xxbos xxxfldtitle xxmaj grafana xxmaj kairosdb xxmaj top n rows xxxfldbody xxmaj when xxmaj grafana pulls the data it shows all the rows returned by the query , so can we please have a query option with something like xxunk ? xxmaj so we can only show limited number of rows on xxmaj grafana unlike now it just gets and shows everything . i have also requested a xxup ui option with xxmaj grafana guys where we can choose the number of rows we want to see under the graph , cheers,xxbos xxxfldtitle xxmaj graph request : mouseover highlight curve . xxxfldbody xxmaj it would be very nice , is mouseover of an item in graph legend ( to the left ) , or mouseover a graphed value ( with checkbox like xxup xxunk ) - would plot that value with double thickness . xxmaj that would make it easy to identify line for each value .,xxbos xxxfldtitle xxmaj graphite template to handle ip - address and hostname xxxfldbody xxmaj are there any plans to improve the graphite template logic ? xxmaj we are sending graphite data that contains xxup ip address and hostname ( xxunk , xxunk , etc ) , since those values have dot 's in them , it makes it difficult to identify tags for those graphite values . xxmaj one other issue we are having is identifying multiple tags in the middle of the graphite string to create a measurement .,xxbos xxxfldtitle xxmaj graphs : xxunk xxxfldbody xxmaj project : xxmaj graphs \n",
       "  xxmaj job : xxup uat \n",
       "  xxmaj env : xxup uat \n",
       "  xxmaj region : fxlabs / xxup us_west_1 \n",
       "  xxmaj result : fail \n",
       "  xxmaj status xxmaj code : 400 \n",
       "  xxmaj headers : xxunk x - xxup xss - xxmaj protection=[1 ; mode = block ] , xxmaj cache - xxmaj control=[no - cache , no - store , max - age=0 , must - revalidate ] , xxmaj pragma=[no - cache ] , xxmaj expires=[0 ] , x - xxmaj frame - options=[deny ] , xxunk xxmaj transfer - xxmaj encoding=[chunked ] , date=[tue , 02 xxmaj oct 2018 xxunk xxup gmt ] } \n",
       "  xxmaj endpoint : * xxup url * xxxlnkhb xxunk xxxlnkhe \n",
       "  xxmaj request : \n",
       "  xxmaj response : \n",
       "  xxxjson \n",
       "  xxmaj logs : \n",
       "  xxmaj assertion xxxatmention = = 403 ] resolved - to [ 400 = = 403 ] result [ xxmaj failed ] --- xxup fx xxmaj bot ---\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: lang_model;\n",
       "\n",
       "Valid: LabelList (1862119 items)\n",
       "x: LMTextList\n",
       "xxbos xxxfldtitle xxmaj gopi xxmaj episode 98 xxxfldbody xxmaj gopi xxmaj episode 98 xxxhtml * xxup url * xxxlnkhb ift.tt xxxlnkhe xxxhtml via xxmaj juragan xxmaj sinopsis * xxup url * xxxlnkhb ift.tt xxxlnkhe xxxhtml xxmaj december 17 , 2016 at xxup xxunk,xxbos xxxfldtitle xxmaj grabber with default xxunk model xxxfldbody xxxhm xxmaj overview \n",
       "  i want to use the default xxunk model ( loaded via dll ) to work with the grabber script . xxmaj the xxunk - demo uses xxunk controller block - shaped prefabs to add the grabber script , but i would like to actually use the default models . xxmaj how would i go about doing so ? \n",
       "  xxxhm xxmaj unity xxmaj editor xxmaj version \n",
       "  xxunk \n",
       "  xxxhm xxmaj mixed xxmaj reality xxmaj toolkit xxmaj release xxmaj version \n",
       "  xxunk xxmaj hot xxmaj fix,xxbos xxxfldtitle graphql integration xxxfldbody xxmaj hi ! xxmaj this project looks really promising to build a modern webapp 😊 i 've been hoping for something like this for a long time ! xxmaj however my first criterion is integrating with a graphql backend , which i even plan to be a hosted backend ( xxmaj graphcool xxxlnkhb * xxup url * xxxlnkhe ) . i suppose it 's not possible right now to use xxmaj xxunk in conjunction with xxmaj graphcool , but could it be considered in the design ? xxmaj the best would be to come up with a standard which can be plugged into any graphql backend ( hosted or own ) . xxmaj thanks so much and all the best,xxbos xxxfldtitle xxmaj grass toolbox filter input is n't labelled xxxfldbody xxxhr xxmaj author xxmaj name : xxunk - ( xxunk - ) xxmaj original xxmaj redmine xxmaj issue : xxunk , * xxup url * xxxlnkhb issues.qgis.org xxxlnkhe \n",
       "  xxxhr xxmaj if you open the xxup grass tools and choose the module list tab , there 's a text input field below the list which filters the list of modules . xxmaj however there 's no clue that it 's a filter box ! xxmaj we had some students confused by this on a course recently . \n",
       "  xxmaj needs a xxmaj filter : label on that line . xxmaj relevant xxup ui file is xxunk i guess .,xxbos xxxfldtitle xxmaj great program -- problems with kotlin xxxfldbody xxmaj quickly trying out your program - awesome . a few quick problems : decompiling a directory of kotlin ... a crash and some mis - ordered xxunk . crash : \n",
       "  xxunk xxxlnkhb github.com xxxlnkhe xxmaj xxunk : \n",
       "  xxup xxunk xxxlnkhb github.com xxxlnkhe xxunk xxxlnkhb github.com xxxlnkhe\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: lang_model;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): Transformer(\n",
       "    (encoder): Embedding(60003, 768)\n",
       "    (pos_enc): Embedding(512, 768)\n",
       "    (drop_emb): Dropout(p=0.1)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=768, out_features=60003, bias=False)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fe3d6cc7b70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('lang_model_test'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (16385650 items)\n",
       "x: LMTextList\n",
       "xxbos xxxfldtitle xxunk throws exception when adding product via xxup api xxxfldbody xxmaj if xxmaj google xxmaj contents xxmaj experiments is enabled , adding a product using the xxxcdb xxup v1 / products / xxxcde endpoint causes xxunk xxxfilepath line 117 to throw xxxcdb invalidargumentexception xxxcde . xxmaj with contents experiments disabled the product add completes successfully . xxmaj example valid request json : \n",
       "  xxxcdb \" product \" : xxxjson \n",
       "  xxxcde,xxbos xxxfldtitle xxmaj grafana xxmaj kairosdb xxmaj top n rows xxxfldbody xxmaj when xxmaj grafana pulls the data it shows all the rows returned by the query , so can we please have a query option with something like xxunk ? xxmaj so we can only show limited number of rows on xxmaj grafana unlike now it just gets and shows everything . i have also requested a xxup ui option with xxmaj grafana guys where we can choose the number of rows we want to see under the graph , cheers,xxbos xxxfldtitle xxmaj graph request : mouseover highlight curve . xxxfldbody xxmaj it would be very nice , is mouseover of an item in graph legend ( to the left ) , or mouseover a graphed value ( with checkbox like xxup xxunk ) - would plot that value with double thickness . xxmaj that would make it easy to identify line for each value .,xxbos xxxfldtitle xxmaj graphite template to handle ip - address and hostname xxxfldbody xxmaj are there any plans to improve the graphite template logic ? xxmaj we are sending graphite data that contains xxup ip address and hostname ( xxunk , xxunk , etc ) , since those values have dot 's in them , it makes it difficult to identify tags for those graphite values . xxmaj one other issue we are having is identifying multiple tags in the middle of the graphite string to create a measurement .,xxbos xxxfldtitle xxmaj graphs : xxunk xxxfldbody xxmaj project : xxmaj graphs \n",
       "  xxmaj job : xxup uat \n",
       "  xxmaj env : xxup uat \n",
       "  xxmaj region : fxlabs / xxup us_west_1 \n",
       "  xxmaj result : fail \n",
       "  xxmaj status xxmaj code : 400 \n",
       "  xxmaj headers : xxunk x - xxup xss - xxmaj protection=[1 ; mode = block ] , xxmaj cache - xxmaj control=[no - cache , no - store , max - age=0 , must - revalidate ] , xxmaj pragma=[no - cache ] , xxmaj expires=[0 ] , x - xxmaj frame - options=[deny ] , xxunk xxmaj transfer - xxmaj encoding=[chunked ] , date=[tue , 02 xxmaj oct 2018 xxunk xxup gmt ] } \n",
       "  xxmaj endpoint : * xxup url * xxxlnkhb xxunk xxxlnkhe \n",
       "  xxmaj request : \n",
       "  xxmaj response : \n",
       "  xxxjson \n",
       "  xxmaj logs : \n",
       "  xxmaj assertion xxxatmention = = 403 ] resolved - to [ 400 = = 403 ] result [ xxmaj failed ] --- xxup fx xxmaj bot ---\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: lang_model;\n",
       "\n",
       "Valid: LabelList (1862119 items)\n",
       "x: LMTextList\n",
       "xxbos xxxfldtitle xxmaj gopi xxmaj episode 98 xxxfldbody xxmaj gopi xxmaj episode 98 xxxhtml * xxup url * xxxlnkhb ift.tt xxxlnkhe xxxhtml via xxmaj juragan xxmaj sinopsis * xxup url * xxxlnkhb ift.tt xxxlnkhe xxxhtml xxmaj december 17 , 2016 at xxup xxunk,xxbos xxxfldtitle xxmaj grabber with default xxunk model xxxfldbody xxxhm xxmaj overview \n",
       "  i want to use the default xxunk model ( loaded via dll ) to work with the grabber script . xxmaj the xxunk - demo uses xxunk controller block - shaped prefabs to add the grabber script , but i would like to actually use the default models . xxmaj how would i go about doing so ? \n",
       "  xxxhm xxmaj unity xxmaj editor xxmaj version \n",
       "  xxunk \n",
       "  xxxhm xxmaj mixed xxmaj reality xxmaj toolkit xxmaj release xxmaj version \n",
       "  xxunk xxmaj hot xxmaj fix,xxbos xxxfldtitle graphql integration xxxfldbody xxmaj hi ! xxmaj this project looks really promising to build a modern webapp 😊 i 've been hoping for something like this for a long time ! xxmaj however my first criterion is integrating with a graphql backend , which i even plan to be a hosted backend ( xxmaj graphcool xxxlnkhb * xxup url * xxxlnkhe ) . i suppose it 's not possible right now to use xxmaj xxunk in conjunction with xxmaj graphcool , but could it be considered in the design ? xxmaj the best would be to come up with a standard which can be plugged into any graphql backend ( hosted or own ) . xxmaj thanks so much and all the best,xxbos xxxfldtitle xxmaj grass toolbox filter input is n't labelled xxxfldbody xxxhr xxmaj author xxmaj name : xxunk - ( xxunk - ) xxmaj original xxmaj redmine xxmaj issue : xxunk , * xxup url * xxxlnkhb issues.qgis.org xxxlnkhe \n",
       "  xxxhr xxmaj if you open the xxup grass tools and choose the module list tab , there 's a text input field below the list which filters the list of modules . xxmaj however there 's no clue that it 's a filter box ! xxmaj we had some students confused by this on a course recently . \n",
       "  xxmaj needs a xxmaj filter : label on that line . xxmaj relevant xxup ui file is xxunk i guess .,xxbos xxxfldtitle xxmaj great program -- problems with kotlin xxxfldbody xxmaj quickly trying out your program - awesome . a few quick problems : decompiling a directory of kotlin ... a crash and some mis - ordered xxunk . crash : \n",
       "  xxunk xxxlnkhb github.com xxxlnkhe xxmaj xxunk : \n",
       "  xxup xxunk xxxlnkhb github.com xxxlnkhe xxunk xxxlnkhb github.com xxxlnkhe\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: lang_model;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): Transformer(\n",
       "    (encoder): Embedding(60003, 768)\n",
       "    (pos_enc): Embedding(512, 768)\n",
       "    (drop_emb): Dropout(p=0.1)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=768, out_features=60003, bias=False)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fe3d6cc7b70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('lang_model_test'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): Embedding(60003, 768)\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=768, out_features=60003, bias=False)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=False)\n",
       "alpha: 2.0\n",
       "beta: 1.0, ParallelTrainer\n",
       "learn: LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (16385650 items)\n",
       "x: LMTextList\n",
       "xxbos xxxfldtitle xxunk throws exception when adding product via xxup api xxxfldbody xxmaj if xxmaj google xxmaj contents xxmaj experiments is enabled , adding a product using the xxxcdb xxup v1 / products / xxxcde endpoint causes xxunk xxxfilepath line 117 to throw xxxcdb invalidargumentexception xxxcde . xxmaj with contents experiments disabled the product add completes successfully . xxmaj example valid request json : \n",
       "  xxxcdb \" product \" : xxxjson \n",
       "  xxxcde,xxbos xxxfldtitle xxmaj grafana xxmaj kairosdb xxmaj top n rows xxxfldbody xxmaj when xxmaj grafana pulls the data it shows all the rows returned by the query , so can we please have a query option with something like xxunk ? xxmaj so we can only show limited number of rows on xxmaj grafana unlike now it just gets and shows everything . i have also requested a xxup ui option with xxmaj grafana guys where we can choose the number of rows we want to see under the graph , cheers,xxbos xxxfldtitle xxmaj graph request : mouseover highlight curve . xxxfldbody xxmaj it would be very nice , is mouseover of an item in graph legend ( to the left ) , or mouseover a graphed value ( with checkbox like xxup xxunk ) - would plot that value with double thickness . xxmaj that would make it easy to identify line for each value .,xxbos xxxfldtitle xxmaj graphite template to handle ip - address and hostname xxxfldbody xxmaj are there any plans to improve the graphite template logic ? xxmaj we are sending graphite data that contains xxup ip address and hostname ( xxunk , xxunk , etc ) , since those values have dot 's in them , it makes it difficult to identify tags for those graphite values . xxmaj one other issue we are having is identifying multiple tags in the middle of the graphite string to create a measurement .,xxbos xxxfldtitle xxmaj graphs : xxunk xxxfldbody xxmaj project : xxmaj graphs \n",
       "  xxmaj job : xxup uat \n",
       "  xxmaj env : xxup uat \n",
       "  xxmaj region : fxlabs / xxup us_west_1 \n",
       "  xxmaj result : fail \n",
       "  xxmaj status xxmaj code : 400 \n",
       "  xxmaj headers : xxunk x - xxup xss - xxmaj protection=[1 ; mode = block ] , xxmaj cache - xxmaj control=[no - cache , no - store , max - age=0 , must - revalidate ] , xxmaj pragma=[no - cache ] , xxmaj expires=[0 ] , x - xxmaj frame - options=[deny ] , xxunk xxmaj transfer - xxmaj encoding=[chunked ] , date=[tue , 02 xxmaj oct 2018 xxunk xxup gmt ] } \n",
       "  xxmaj endpoint : * xxup url * xxxlnkhb xxunk xxxlnkhe \n",
       "  xxmaj request : \n",
       "  xxmaj response : \n",
       "  xxxjson \n",
       "  xxmaj logs : \n",
       "  xxmaj assertion xxxatmention = = 403 ] resolved - to [ 400 = = 403 ] result [ xxmaj failed ] --- xxup fx xxmaj bot ---\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: lang_model;\n",
       "\n",
       "Valid: LabelList (1862119 items)\n",
       "x: LMTextList\n",
       "xxbos xxxfldtitle xxmaj gopi xxmaj episode 98 xxxfldbody xxmaj gopi xxmaj episode 98 xxxhtml * xxup url * xxxlnkhb ift.tt xxxlnkhe xxxhtml via xxmaj juragan xxmaj sinopsis * xxup url * xxxlnkhb ift.tt xxxlnkhe xxxhtml xxmaj december 17 , 2016 at xxup xxunk,xxbos xxxfldtitle xxmaj grabber with default xxunk model xxxfldbody xxxhm xxmaj overview \n",
       "  i want to use the default xxunk model ( loaded via dll ) to work with the grabber script . xxmaj the xxunk - demo uses xxunk controller block - shaped prefabs to add the grabber script , but i would like to actually use the default models . xxmaj how would i go about doing so ? \n",
       "  xxxhm xxmaj unity xxmaj editor xxmaj version \n",
       "  xxunk \n",
       "  xxxhm xxmaj mixed xxmaj reality xxmaj toolkit xxmaj release xxmaj version \n",
       "  xxunk xxmaj hot xxmaj fix,xxbos xxxfldtitle graphql integration xxxfldbody xxmaj hi ! xxmaj this project looks really promising to build a modern webapp 😊 i 've been hoping for something like this for a long time ! xxmaj however my first criterion is integrating with a graphql backend , which i even plan to be a hosted backend ( xxmaj graphcool xxxlnkhb * xxup url * xxxlnkhe ) . i suppose it 's not possible right now to use xxmaj xxunk in conjunction with xxmaj graphcool , but could it be considered in the design ? xxmaj the best would be to come up with a standard which can be plugged into any graphql backend ( hosted or own ) . xxmaj thanks so much and all the best,xxbos xxxfldtitle xxmaj grass toolbox filter input is n't labelled xxxfldbody xxxhr xxmaj author xxmaj name : xxunk - ( xxunk - ) xxmaj original xxmaj redmine xxmaj issue : xxunk , * xxup url * xxxlnkhb issues.qgis.org xxxlnkhe \n",
       "  xxxhr xxmaj if you open the xxup grass tools and choose the module list tab , there 's a text input field below the list which filters the list of modules . xxmaj however there 's no clue that it 's a filter box ! xxmaj we had some students confused by this on a course recently . \n",
       "  xxmaj needs a xxmaj filter : label on that line . xxmaj relevant xxup ui file is xxunk i guess .,xxbos xxxfldtitle xxmaj great program -- problems with kotlin xxxfldbody xxmaj quickly trying out your program - awesome . a few quick problems : decompiling a directory of kotlin ... a crash and some mis - ordered xxunk . crash : \n",
       "  xxunk xxxlnkhb github.com xxxlnkhe xxmaj xxunk : \n",
       "  xxup xxunk xxxlnkhb github.com xxxlnkhe xxunk xxxlnkhb github.com xxxlnkhe\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: lang_model;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): Transformer(\n",
       "    (encoder): Embedding(60003, 768)\n",
       "    (pos_enc): Embedding(512, 768)\n",
       "    (drop_emb): Dropout(p=0.1)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=768, out_features=60003, bias=False)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fe3d6cc7b70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('lang_model_test'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): Embedding(60003, 768)\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=768, out_features=60003, bias=False)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=False)], layer_groups=[Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1)\n",
       "      (drop_res): Dropout(p=0.1)\n",
       "      (ln): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): Embedding(60003, 768)\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=768, out_features=60003, bias=False)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.to_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='184299' class='' max='395986', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      46.54% [184299/395986 14:40:30<16:51:20 3.4578]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(cyc_len=1,\n",
    "                    max_lr=1e-3,\n",
    "                    tot_epochs=10,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('lang_model_test')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
