{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# so I don't \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"  #prevent access to GPU for inference\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 150\n",
    "pd.options.display.max_colwidth = 500\n",
    "import json\n",
    "from mdparse import transform_pre_rules, compose\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "assert not torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at Data For Kubeflow/Kubeflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Kubeflow Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " See the query in [GCP BigQuery Console](https://console.cloud.google.com/bigquery?sq=1073071082706:92b4ec67dbf5441ba95eb5b9d77e8993)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'https://storage.googleapis.com/issue_label_bot/kubeflow_issues/000000000000.csv')\n",
    "# filter for kubeflow/kubeflow\n",
    "kfdf = df[df.repo.apply(lambda x: x.split('/')[1] =='kubeflow')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten list of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack the lists of labels and flatten\n",
    "def unpack_list(x):\n",
    "    \"convert list as string into list.\"\n",
    "    if x == '':\n",
    "        return 'no_labels'\n",
    "    else:\n",
    "        return json.loads(x)\n",
    "\n",
    "#flatten lists\n",
    "labels = []\n",
    "label_series = kfdf.labels.apply(lambda x: unpack_list(x))\n",
    "for x in label_series:\n",
    "    labels.extend(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 / Bottom 10 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "priority/p1           534\n",
       "priority/p2           148\n",
       "area/jupyter          142\n",
       "platform/gcp          128\n",
       "area/kfctl            114\n",
       "release/0.3.0          98\n",
       "community/question     96\n",
       "area/0.4.0             90\n",
       "area/bootstrap         83\n",
       "priority/p0            62\n",
       "Name: labels, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "area/horovod              1\n",
       "area/centraldashbosard    1\n",
       "area/design               1\n",
       "area/chainer              1\n",
       "cloud/azure               1\n",
       "area/kubebench            1\n",
       "area/0.2.0                1\n",
       "prirority/p1              1\n",
       "p1-important              1\n",
       "platform/minikf           1\n",
       "Name: labels, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_counts = pd.DataFrame({'labels': labels}).labels.value_counts()\n",
    "display(label_counts.head(10))\n",
    "display(label_counts.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Borrowed this from nb 2\n",
    "def process_dict(dfdict, _):\n",
    "    \"\"\"process the data, but allow failure.\"\"\"\n",
    "    t = compose(transform_pre_rules)\n",
    "    title = dfdict['title']\n",
    "    body = dfdict['body']\n",
    "    try:\n",
    "        text = 'xxxfldtitle '+ t(title) + ' xxxfldbody ' + t(body)\n",
    "    except:\n",
    "        return None\n",
    "    return {'url': dfdict['url'], 'text':text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': '\"https://github.com/kubeflow/kubeflow/issues/574\"',\n",
       "  'text': \"xxxfldtitle tfjobs ui doesn't work behind iap; react app needs support iap? xxxfldbody tfjobs ui is deployed on dev.kubeflow.org. \\\\ r \\\\ r the ui shows up behind iap but its doesn't work \\\\ r - no tfjobs are listed \\\\ r - creating a job via the ui doesn't work. \\\\ r \\\\ r looking at the developer console we see requests to \\\\ r \\\\ r \\\\ r *URL* xxxlnkhb accounts.google.com xxxlnkhe \\\\ r \\\\ r which suggests to me the request is hitting the loadbalancer and being directed to do auth verification to sign in and its getting rejected. \\\\ r \\\\ r so i think one of two things is happening \\\\ r \\\\ r 1. the request is coming from the server running in k8s and incorrectly being redirected to the external loadbalncer and thus hitting iap when it shouldn't be \\\\ r 1. the request is coming from the client and the client needs to be updated to support iap. \\\\ r \\\\ r xxxatmention do you know where the request is coming from? \\\\ r \\\\ r you should be able to access it at \\\\ r *URL* xxxlnkhb dev.kubeflow.org xxxlnkhe\"},\n",
       " {'url': '\"https://github.com/kubeflow/kubeflow/issues/950\"',\n",
       "  'text': \"xxxfldtitle gcp cluster-kubeflow.yaml isn't tested xxxfldbody this is the recommended dm and bootstrapper config for gke deployments. \\\\ r *URL* xxxlnkhb github.com xxxlnkhe \\\\ r it doesn't like that yaml file is used by our e2e tests because it wasn't updated to specify the registry when that change was made to \\\\ r *URL* xxxlnkhb github.com xxxlnkhe \\\\ r there is also another gcp bootstrapper config in that directory \\\\ r \\\\ r our e2e tests are using this dm config \\\\ r *URL* xxxlnkhb github.com xxxlnkhe \\\\ r we do need to make changes to the dm config in order to pull the registry at head. \\\\ r \\\\ r we have two options \\\\ r \\\\ r 1. we could create a separate test for *URL* xxxlnkhb github.com xxxlnkhe 1. we could make the necessary modifications to *URL* xxxlnkhb github.com xxxlnkhe \\\\ r we could use a simple shell script that runs jq to make the necessary field changes \\\\ r \\\\ r i prefer 2. if we use jq then we could update the instructions *URL* xxxlnkhb github.com xxxlnkhe to use the same jq commands. \\\\ r \\\\ r xxxatmention thoughts?\"}]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_issue_texts = [process_dict(x, 0) for x in kfdf.to_dict(orient='rows')]\n",
    "processed_issue_texts[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: you can export a lightweight learner for inference per https://docs.fast.ai/tutorial.inference.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.models import AWD_LSTM\n",
    "from fastai.text import TextLMDataBunch as lmdb, load_data\n",
    "from fastai.text.learner import language_model_learner\n",
    "from fastai.basic_train import load_learner\n",
    "path = Path('lang_model_onecycle/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_through(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't have to execute the below cell anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_lm = load_data(path, bs=128)\n",
    "\n",
    "# learn = language_model_learner(data=data_lm,\n",
    "#                                arch=AWD_LSTM,\n",
    "#                                pretrained=False)\n",
    "\n",
    "# learn.load('bestmodel')\n",
    "\n",
    "# learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.reset() # so the hidden states reset between predictions\n",
    "_ = learn.model.eval() # turn off dropout, etc. only need to do this after loading model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "Fastai encoder produces a tuple of two lists `raw_output` and `output`.  see [this reference](https://github.com/fastai/fastai/blob/master/fastai/text/models/awd_lstm.py#L123)  `raw_output` are the hidden states emitted for each element of the sequence without dropout.  Because you are turning off dropout during inference with `.eval()`, it really doesn't matter which one you get as they will both be the same (if they are not, this is a bug). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxxfldtitle v1alpha2 implement condition update xxxfldbody we should update the conditions according to the status. \\ r \\ r / cc xxxatmention \n"
     ]
    }
   ],
   "source": [
    "ex = processed_issue_texts[0]['text']\n",
    "print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,    22, 35652,   454,  1619,   173,    23,    64,    66,   173,\n",
       "             9,  2127,  1099,    13,     9,   357,    10,    50,   696,    50,\n",
       "           696,    37,  1075,   118]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_numericalized_x,  ex_numericalized_y = learn.data.one_item(ex)\n",
    "ex_numericalized_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two output tensors should be the same, this is testing that the model state is being reset correctly between predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0129,  0.0362,  0.0007,  ..., -0.0754, -0.0074,  0.0045],\n",
      "         [-0.0251,  0.0263,  0.0664,  ..., -0.0272,  0.0092,  0.0330],\n",
      "         [ 0.0580,  0.0300,  0.0196,  ..., -0.0416,  0.0290,  0.0129],\n",
      "         ...,\n",
      "         [-0.0111,  0.0130,  0.0432,  ..., -0.0640,  0.1140,  0.0357],\n",
      "         [-0.0105, -0.0146,  0.0293,  ..., -0.1969,  0.2049,  0.0006],\n",
      "         [-0.0057,  0.0225,  0.0220,  ..., -0.1356, -0.0231, -0.0011]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 24, 400])\n"
     ]
    }
   ],
   "source": [
    "encoder = learn.model[0]\n",
    "rep = encoder.forward(ex_numericalized_x)[-1][-1]\n",
    "print(rep)\n",
    "print(rep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0129,  0.0362,  0.0007,  ..., -0.0754, -0.0074,  0.0045],\n",
      "         [-0.0251,  0.0263,  0.0664,  ..., -0.0272,  0.0092,  0.0330],\n",
      "         [ 0.0580,  0.0300,  0.0196,  ..., -0.0416,  0.0290,  0.0129],\n",
      "         ...,\n",
      "         [-0.0111,  0.0130,  0.0432,  ..., -0.0640,  0.1140,  0.0357],\n",
      "         [-0.0105, -0.0146,  0.0293,  ..., -0.1969,  0.2049,  0.0006],\n",
      "         [-0.0057,  0.0225,  0.0220,  ..., -0.1356, -0.0231, -0.0011]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 24, 400])\n"
     ]
    }
   ],
   "source": [
    "learn.model.reset()\n",
    "rep = encoder.forward(ex_numericalized_x)[-1][-1]\n",
    "print(rep)\n",
    "print(rep.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numericalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7db2ad8c1654f2dbcbddf72b2ee1b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1384), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# index into [0] b/c we don't care about the y value.\n",
    "num_x = []\n",
    "\n",
    "for x in tqdm_notebook(processed_issue_texts, total=len(processed_issue_texts)):\n",
    "    num_x.extend(learn.data.one_item(x)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d6f4e3d2c846d1a760729ef3e6071a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1384), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reps=[]\n",
    "for x in tqdm_notebook(num_x, total=len(num_x)):\n",
    "    reps.extend(encoder.forward(x[None, :])[-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "class IssueRepresentation:\n",
    "    \n",
    "    def __init__(self, tensor:torch.tensor) -> torch.tensor:\n",
    "        self.tensor=tensor\n",
    "    \n",
    "    @property\n",
    "    def mean(self):\n",
    "        return torch.mean(self.tensor, 0)\n",
    "    \n",
    "    @property\n",
    "    def max(self):\n",
    "        return torch.max(self.tensor, 0)[0]\n",
    "    \n",
    "    @property\n",
    "    def last(self):\n",
    "        return self.tensor[-1,:]\n",
    "    \n",
    "    @property\n",
    "    def concat(self):\n",
    "        return torch.cat([self.mean, self.max, self.last])\n",
    "\n",
    "class IssueRepresentation_List:\n",
    "    def __init__(self, irl=List[torch.tensor]):\n",
    "        self.irl = [IssueRepresentation(x) for x in irl]\n",
    "    \n",
    "    @property\n",
    "    def mean(self):\n",
    "        return torch.stack([x.mean for x in self.irl])\n",
    "    \n",
    "    @property\n",
    "    def max(self):\n",
    "        return torch.stack([x.max for x in self.irl])\n",
    "    \n",
    "    @property\n",
    "    def last(self):\n",
    "        return torch.stack([x.last for x in self.irl])\n",
    "    \n",
    "    @property\n",
    "    def concat(self):\n",
    "        return torch.stack([x.concat for x in self.irl])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "irl = IssueRepresentation_List(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open('irl.pkl', 'wb') as f:\n",
    "    pkl.dump(irl, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See if Naive One Shot Learning Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open('irl.pkl', 'rb') as f:\n",
    "    irl = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542 issues w/o labels out of 1384 total issues.\n"
     ]
    }
   ],
   "source": [
    "## == True converts it into a 0/1 indices array\n",
    "candidates_to_label = torch.tensor((kfdf.labels == '[]').values) == True\n",
    "\n",
    "print(f'{candidates_to_label.sum()} issues w/o labels out of {len(kfdf)} total issues.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_label_reps = irl.concat[candidates_to_label]\n",
    "label_reps = irl.concat[~candidates_to_label]\n",
    "\n",
    "assert (no_label_reps.shape[0] + label_reps.shape[0]) == len(kfdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask = kfdf.labels != '[]'\n",
    "\n",
    "labeled_df = kfdf[label_mask].reset_index(drop=True)\n",
    "no_label_df = kfdf[~label_mask].reset_index(drop=True)\n",
    "\n",
    "assert len(labeled_df) + len(no_label_df) == len(kfdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class oneshotlabeler:\n",
    "    def __init__(self, vecs, refdf):\n",
    "        assert vecs.shape[0] == len(refdf)\n",
    "        self.vecs = vecs\n",
    "        self.refdf = refdf.reset_index(drop=True)\n",
    "        self.cs = CosineSimilarity()\n",
    "    \n",
    "    def query(self, vec):\n",
    "        assert vec.ndim == 1\n",
    "        sims = cs.forward(vec.unsqueeze(0), self.vecs)\n",
    "        idxs = sims.argsort(descending=True)\n",
    "        ranked_sims = sims[idxs]\n",
    "        \n",
    "        closest_idx = idxs[0].item()\n",
    "        ref_issue = self.refdf.iloc[closest_idx]\n",
    "        \n",
    "        msg = []\n",
    "        msg.append(f'\\n## Prediction:\\n')\n",
    "        msg.append(f'**Predicted Labels**: {json.loads(ref_issue.labels)}\\n')\n",
    "        msg.append(f'**Cosine similarity (0-1)**: {ranked_sims[0]:.2f}\\n')\n",
    "        msg.append(f'**Closest Issue URL**: {json.loads(ref_issue.url)}\\n')\n",
    "        msg.append(f'**Closest Issue Title**: {ref_issue.title}\\n')\n",
    "        msg.append(f'**Closest Issue Body**:\\n {ref_issue.body[:600]}')\n",
    "        display(Markdown('\\n'.join(msg)))\n",
    "        \n",
    "    def random_prediction(self, no_label_df, no_label_vec):\n",
    "        assert len(no_label_df) == no_label_vec.shape[0]\n",
    "        sample = no_label_df.sample(1)\n",
    "        idx = sample.index.values[0]\n",
    "        \n",
    "        msg = []\n",
    "        msg.append(f'\\n## Un-Labeled Target Issue To Predict:\\n')\n",
    "        msg.append(f'**Title:** {sample.title.values[0]}\\n')\n",
    "        msg.append(f'**Body:**\\n {sample.body.values[0][:600]}\\n')\n",
    "        msg.append(f'**URL:** {sample.url.values[0]}')\n",
    "        display(Markdown('\\n'.join(msg)))\n",
    "        \n",
    "        self.query(no_label_vec[idx, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(no_label_df) == no_label_reps.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol = oneshotlabeler(vecs=label_reps, \n",
    "                    refdf = labeled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Un-Labeled Target Issue To Predict:\n",
       "\n",
       "**Title:** gke deploy test failed because of insufficient quota\n",
       "\n",
       "**Body:**\n",
       " http://testing-argo.kubeflow.org/workflows/kubeflow-test-infra/kubeflow-presubmit-kubeflow-gke-deploy-840-6c8e8a7-1599-d299?tab=workflow&nodeid=kubeflow-presubmit-kubeflow-gke-deploy-840-6c8e8a7-1599-d299-213896030\\r \\r in  840 \\r \\r    \\r error:  gcloud.deployment-manager.deployments.create  error in operation  operation-1526938804121-56cbe25036da9-15fe77cd-70641b75 : errors:\\r - code: resource_error\\r  location: /deployments/z40-6c8e8a7-1599-d299/resources/cpu-pool-v1\\r  message: \\ {\\\\\\ resourcetype\\\\\\ :\\\\\\ container.v1.nodepool\\\\\\ ,\\\\\\ resourceerrorcode\\\\\\ :\\\\\\ 403\\\\\\ \\\\\\r    ,\\\\\\ resourcee\n",
       "\n",
       "**URL:** \"https://github.com/kubeflow/kubeflow/issues/842\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Prediction:\n",
       "\n",
       "**Predicted Labels**: ['area/build-release', 'area/testing']\n",
       "\n",
       "**Cosine similarity (0-1)**: 0.97\n",
       "\n",
       "**Closest Issue URL**: https://github.com/kubeflow/kubeflow/issues/822\n",
       "\n",
       "**Closest Issue Title**: gke deploy test failed because another process was deleting\n",
       "\n",
       "**Closest Issue Body**:\n",
       " https://k8s-gubernator.appspot.com/build/kubernetes-jenkins/pr-logs/pull/kubeflow_kubeflow/814/kubeflow-presubmit/1558/\\r \\r    \\r error:  gcloud.deployment-manager.deployments.create  error in operation  operation-1526578740627-56c6a4f8e8639-3b63db3e-5d7cb2dd : e\\r rrors:\\r - code: resource_error\\r  location: /deployments/z14-a015e87-1558-6462/resources/cpu-pool-v1\\r  message: \\ {\\\\\\ resourcetype\\\\\\ :\\\\\\ container.v1.nodepool\\\\\\ ,\\\\\\ resourceerrorcode\\\\\\ :\\\\\\ 400\\\\\\ \\\\\\r    ,\\\\\\ resourceerrormessage\\\\\\ :{\\\\\\ code\\\\\\ :400,\\\\\\ message\\\\\\ :\\\\\\ operation operation-1526578878193-71024dcd\\\\\\r    \\\\"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ol.random_prediction(no_label_df=no_label_df,\n",
    "                     no_label_vec=no_label_reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>repo</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>num_labels</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>\"https://github.com/kubeflow/kubeflow/issues/1542\"</td>\n",
       "      <td>kubeflow/kubeflow</td>\n",
       "      <td>add jsonnet tests for all libsonnet files</td>\n",
       "      <td>many libsonnet files do not have tests. tests should be added for the following:\\r \\r kubeflow/core/ambassador.libsonnet\\r kubeflow/core/centraldashboard.libsonnet\\r kubeflow/core/cert-manager.libsonnet\\r kubeflow/core/cloud-endpoints.libsonnet\\r kubeflow/core/echo-server.libsonnet\\r kubeflow/core/google-cloud-filestore-pv.libsonnet\\r kubeflow/core/jupyterhub.libsonnet\\r kubeflow/core/metric-collector.libsonnet\\r kubeflow/core/prometheus.libsonnet\\r kubeflow/core/spartakus.libsonnet\\r kubefl...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url               repo  \\\n",
       "527  \"https://github.com/kubeflow/kubeflow/issues/1542\"  kubeflow/kubeflow   \n",
       "\n",
       "                                         title  \\\n",
       "527  add jsonnet tests for all libsonnet files   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    body  \\\n",
       "527  many libsonnet files do not have tests. tests should be added for the following:\\r \\r kubeflow/core/ambassador.libsonnet\\r kubeflow/core/centraldashboard.libsonnet\\r kubeflow/core/cert-manager.libsonnet\\r kubeflow/core/cloud-endpoints.libsonnet\\r kubeflow/core/echo-server.libsonnet\\r kubeflow/core/google-cloud-filestore-pv.libsonnet\\r kubeflow/core/jupyterhub.libsonnet\\r kubeflow/core/metric-collector.libsonnet\\r kubeflow/core/prometheus.libsonnet\\r kubeflow/core/spartakus.libsonnet\\r kubefl...   \n",
       "\n",
       "     num_labels labels  \n",
       "527           0     []  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = no_label_df.sample(1)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n## Un-Labeled Target Issue To Predict:\\n',\n",
       " '**Title:** feast  feature store  and kubeflow',\n",
       " \"**Body:**\\n at  gojek  https://www.gojek.io/  we've recently open sourced a software project called  feast  https://github.com/gojek/feast , an internal feature store for managing, storing, and discovering features for machine learning. the software was jointly developed by gojek and google, and the first release is currently running in production at gojek. we are open sourcing the software because we've seen many teams face the same challenges with features as we have, and we'd love to get feedback from the community both on what we have built, and what we are planning to build.\\\\r \\\\r feast is meant to be\",\n",
       " '**URL:** \"https://github.com/kubeflow/kubeflow/issues/2141\"']"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "msg = []\n",
    "msg.append(f'\\n## Un-Labeled Target Issue To Predict:\\n')\n",
    "msg.append(f'**Title:** {sample.title.values[0]}')\n",
    "msg.append(f'**Body:**\\n {sample.body.values[0][:600]}')\n",
    "msg.append(f'**URL:** {sample.url.values[0]}')\n",
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Prediction:\n",
       "\n",
       "**Predicted Labels**: ['area/0.4.0', 'area/inference', 'priority/p1']\n",
       "\n",
       "**Cosine similarity (0-1)**: 0.92\n",
       "\n",
       "**Closest Issue URL**: https://github.com/kubeflow/kubeflow/issues/1036\n",
       "\n",
       "**Closest Issue Title**: tfserving supports collection of metrics with prometheus\n",
       "\n",
       "**Closest Issue Body**:\n",
       " we'd like tfserving to support exporting relevant metrics in a k8s/prometheus compatible manner.\\r \\r here are some relevant ussues tracking the features in tf serving\\r \\r tensorflow/serving 462 - server metrics\\r     cfegly's  comment  https://github.com/tensorflow/serving/issues/462 issuecomment-367594255  is a good summary of what we would like\\r tensorflow/serving 800 - collect servable metrics\\r \\r"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ol.query(no_label_reps[417, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1384, 1200])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_vec = irl.concat\n",
    "avg_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.distance import CosineSimilarity\n",
    "cs = CosineSimilarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = cs.forward(avg_vec[544, :].unsqueeze(0), avg_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 544,  963,  352,  ...,  772, 1020,  971])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = tst.argsort(descending=True)\n",
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.9303, 0.9193,  ..., 0.7091, 0.7025, 0.7025],\n",
       "       grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfdf.reset_index(drop=True, inplace=True) # make sure index is 0 based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \"https://github.com/kubeflow/kubeflow/issues/1412\"\n",
       "repo                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            kubeflow/kubeflow\n",
       "title                                                                                                                                                                                                                                                                                                                                                                                                                                                                           how to spawn the jupyter container as a root user\n",
       "body          hi,\\r \\r as part of my development, i would like to spawn the jupyter container as a root user. \\r is there any way to do so.\\r i tried to by changing the following in kubeform_spawner.py, \\r \\r > c.kubespawner.singleuser_uid = 0\\r > c.kubespawner.singleuser_fs_gid = 0\\r \\r but didn't help, with this change container getting exited with following error :\\r checking if /home/jovyan volume needs init...\\r .../home/jovyan already has content...\\r ...done\\r usermod: no changes\\r execute the comm...\n",
       "num_labels                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      2\n",
       "labels                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [\"area/jupyter\", \"community/question\"]\n",
       "Name: 963, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfdf.iloc[963]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'repo', 'title', 'body', 'num_labels', 'labels'], dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfdf.iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closest issue: https://github.com/kubeflow/kubeflow/issues/1412\n",
      "\n",
      "Title: how to spawn the jupyter container as a root user\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 963\n",
    "print(f'closest issue: {json.loads(kfdf.iloc[idx].url)}\\n')\n",
    "print(f'Title: {kfdf.iloc[idx].title}\\n')\n",
    "\n",
    "print(f'cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>repo</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>num_labels</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>\"https://github.com/kubeflow/kubeflow/issues/1285\"</td>\n",
       "      <td>kubeflow/kubeflow</td>\n",
       "      <td>how can we change the tensorflow image in kubeflow?</td>\n",
       "      <td>i have created a model file and it was built in tensorflow 1.8. when i try to serve the model and i apply \\ ks apply cloud -c serve\\  i see that it is using tensorflow 1.7 image  gcr.io/kubeflow-images-public/tensorflow-serving-1.7 . how can change the tensorflow-serving image ?</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>\"https://github.com/kubeflow/kubeflow/issues/200\"</td>\n",
       "      <td>kubeflow/kubeflow</td>\n",
       "      <td>error server is unable to handle tensorflow.org/v1alpha1, kind=tfjob</td>\n",
       "      <td>more information:\\r \\r kubectl get pods --namespace=${namespace}\\r name                                ready     status    restarts   age\\r ambassador-1695609295-7d7ml         2/2       running   0          23m\\r ambassador-1695609295-dblhh         2/2       running   0          23m\\r ambassador-1695609295-m0bzw         2/2       running   0          23m\\r tf-hub-0                            1/1       running   0          23m\\r tf-job-dashboard-4279538329-vsxl8   1/1       running   0       ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>\"https://github.com/kubeflow/kubeflow/issues/1768\"</td>\n",
       "      <td>kubeflow/kubeflow</td>\n",
       "      <td>current master version fails when applying platform in gcp</td>\n",
       "      <td>apply platform fails with the below error:\\r - code: resource_error\\r   location: /deployments/kubeflow-tpu/resources/kubeflow-tpu\\r   message: '{\\ resourcetype\\ :\\ container.v1.cluster\\ ,\\ resourceerrorcode\\ :\\ 400\\ ,\\ resourceerrormessage\\ :{\\ code\\ :400,\\ message\\ :\\ cluster.logging_service\\r     was \\\\\\ logging.googleapis.com/kubernetes\\\\\\  but must be one of \\\\\\ \\\\\\ , \\\\\\ none\\\\\\ , \\\\\\ logging.googleapis.com\\\\\\ .\\ ,\\ status\\ :\\ invalid_argument\\ ,\\ statusmessage\\ :\\ bad\\r     request\\ ,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>\"https://github.com/kubeflow/kubeflow/issues/3219\"</td>\n",
       "      <td>kubeflow/kubeflow</td>\n",
       "      <td>set port name to http-xx for all services</td>\n",
       "      <td>istio relies on port name to distinguish http vs tcp services  this affects some authz features .\\r we should make sure the port name is http-xx for all services.\\r see  doc  https://istio.io/help/faq/traffic-management/ naming-port-convention .\\r \\r cc @kunmingg \\r \\r</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>\"https://github.com/kubeflow/kubeflow/issues/2522\"</td>\n",
       "      <td>kubeflow/kubeflow</td>\n",
       "      <td>error when using pytorch in notebooks</td>\n",
       "      <td>hey, \\r \\r when using pytorch  via fastai  in my notebook i get the error:\\r      \\r runtimeerror: traceback  most recent call last :\\r   file \\ /opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\\ , line 138, in _worker_loop\\r     samples = collate_fn  dataset i  for i in batch_indices  \\r   file \\ /opt/conda/lib/python3.6/site-packages/fastai/torch_core.py\\ , line 117, in data_collate\\r     return torch.utils.data.dataloader.default_collate to_data batch  \\r   file \\ /opt...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url               repo  \\\n",
       "540  \"https://github.com/kubeflow/kubeflow/issues/1285\"  kubeflow/kubeflow   \n",
       "541   \"https://github.com/kubeflow/kubeflow/issues/200\"  kubeflow/kubeflow   \n",
       "542  \"https://github.com/kubeflow/kubeflow/issues/1768\"  kubeflow/kubeflow   \n",
       "543  \"https://github.com/kubeflow/kubeflow/issues/3219\"  kubeflow/kubeflow   \n",
       "544  \"https://github.com/kubeflow/kubeflow/issues/2522\"  kubeflow/kubeflow   \n",
       "\n",
       "                                                                    title  \\\n",
       "540                   how can we change the tensorflow image in kubeflow?   \n",
       "541  error server is unable to handle tensorflow.org/v1alpha1, kind=tfjob   \n",
       "542            current master version fails when applying platform in gcp   \n",
       "543                             set port name to http-xx for all services   \n",
       "544                                 error when using pytorch in notebooks   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    body  \\\n",
       "540                                                                                                                                                                                                                              i have created a model file and it was built in tensorflow 1.8. when i try to serve the model and i apply \\ ks apply cloud -c serve\\  i see that it is using tensorflow 1.7 image  gcr.io/kubeflow-images-public/tensorflow-serving-1.7 . how can change the tensorflow-serving image ?   \n",
       "541  more information:\\r \\r kubectl get pods --namespace=${namespace}\\r name                                ready     status    restarts   age\\r ambassador-1695609295-7d7ml         2/2       running   0          23m\\r ambassador-1695609295-dblhh         2/2       running   0          23m\\r ambassador-1695609295-m0bzw         2/2       running   0          23m\\r tf-hub-0                            1/1       running   0          23m\\r tf-job-dashboard-4279538329-vsxl8   1/1       running   0       ...   \n",
       "542  apply platform fails with the below error:\\r - code: resource_error\\r   location: /deployments/kubeflow-tpu/resources/kubeflow-tpu\\r   message: '{\\ resourcetype\\ :\\ container.v1.cluster\\ ,\\ resourceerrorcode\\ :\\ 400\\ ,\\ resourceerrormessage\\ :{\\ code\\ :400,\\ message\\ :\\ cluster.logging_service\\r     was \\\\\\ logging.googleapis.com/kubernetes\\\\\\  but must be one of \\\\\\ \\\\\\ , \\\\\\ none\\\\\\ , \\\\\\ logging.googleapis.com\\\\\\ .\\ ,\\ status\\ :\\ invalid_argument\\ ,\\ statusmessage\\ :\\ bad\\r     request\\ ,...   \n",
       "543                                                                                                                                                                                                                                        istio relies on port name to distinguish http vs tcp services  this affects some authz features .\\r we should make sure the port name is http-xx for all services.\\r see  doc  https://istio.io/help/faq/traffic-management/ naming-port-convention .\\r \\r cc @kunmingg \\r \\r   \n",
       "544  hey, \\r \\r when using pytorch  via fastai  in my notebook i get the error:\\r      \\r runtimeerror: traceback  most recent call last :\\r   file \\ /opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\\ , line 138, in _worker_loop\\r     samples = collate_fn  dataset i  for i in batch_indices  \\r   file \\ /opt/conda/lib/python3.6/site-packages/fastai/torch_core.py\\ , line 117, in data_collate\\r     return torch.utils.data.dataloader.default_collate to_data batch  \\r   file \\ /opt...   \n",
       "\n",
       "     num_labels labels  \n",
       "540           0     []  \n",
       "541           0     []  \n",
       "542           0     []  \n",
       "543           0     []  \n",
       "544           0     []  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfdf[kfdf.labels == '[]'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- Some labels have a fairly high N.  Do we really need few shot for these?\n",
    "- Do you really want to maintain local models for each repo?  If you do should be a seperate service with API endpoint to keep dependencies clean.\n",
    "- First lets see if few shot can even work?\n",
    "- Looks like we might be able to get pretty far on keyword matching and BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBatchEncoder(nn.Module):\n",
    "    \"Create an encoder over `module` that can process a full sentence.\"\n",
    "    def __init__(self, bptt:int, max_len:int, module:nn.Module, pad_idx:int=1):\n",
    "        super().__init__()\n",
    "        self.max_len,self.bptt,self.module,self.pad_idx = max_len,bptt,module,pad_idx\n",
    "\n",
    "    def concat(self, arrs:Collection[Tensor])->Tensor:\n",
    "        \"Concatenate the `arrs` along the batch dimension.\"\n",
    "        return [torch.cat([l[si] for l in arrs], dim=1) for si in range_of(arrs[0])]\n",
    "    \n",
    "    def reset(self): \n",
    "        if hasattr(self.module, 'reset'): self.module.reset()\n",
    "\n",
    "    def forward(self, input:LongTensor)->Tuple[Tensor,Tensor]:\n",
    "        bs,sl = input.size()\n",
    "        self.reset()\n",
    "        raw_outputs,outputs,masks = [],[],[]\n",
    "        for i in range(0, sl, self.bptt):\n",
    "            # encoder emits raw, output\n",
    "            r, o = self.module(input[:,i: min(i+self.bptt, sl)])\n",
    "            if i>(sl-self.max_len):\n",
    "                masks.append(input[:,i: min(i+self.bptt, sl)] == self.pad_idx)\n",
    "                raw_outputs.append(r)\n",
    "                outputs.append(o)\n",
    "        return self.concat(raw_outputs),self.concat(outputs),torch.cat(masks,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.data.vocab.stoi['xxpad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.data.bptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
